{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SPO2 intern.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0FxvDYFKcV0",
        "outputId": "b62d8b3b-d2b3-4b8c-ce1e-636076409e17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd gdrive/MyDrive/Intern bp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBJO3tiIK8qT",
        "outputId": "367a5abb-07ac-420d-82f7-105eeb92e8d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Intern bp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt "
      ],
      "metadata": {
        "id": "BYQKzN97V9H1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "x = pd.read_csv('processed_x.csv')\n",
        "y = pd.read_csv('y unscaled.csv')\n",
        "y_unscaled = pd.read_csv('bp_values_videos_removed.csv')"
      ],
      "metadata": {
        "id": "ElGev1H5Ln7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scale the y values"
      ],
      "metadata": {
        "id": "ZSbuLDhEvK-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "ob9XPFbCukwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "y_scaled = scaler.fit_transform(y)\n",
        "print(y_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5HORk3ruvH2",
        "outputId": "8321ed77-da84-4391-f678-f9c1db1717de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.95 ]\n",
            " [0.95 ]\n",
            " [0.95 ]\n",
            " [0.95 ]\n",
            " [0.95 ]\n",
            " [0.95 ]\n",
            " [0.95 ]\n",
            " [0.95 ]\n",
            " [0.95 ]\n",
            " [0.95 ]\n",
            " [0.95 ]\n",
            " [0.55 ]\n",
            " [0.55 ]\n",
            " [0.55 ]\n",
            " [0.55 ]\n",
            " [0.55 ]\n",
            " [0.55 ]\n",
            " [0.55 ]\n",
            " [0.55 ]\n",
            " [0.55 ]\n",
            " [0.55 ]\n",
            " [0.55 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.73 ]\n",
            " [0.73 ]\n",
            " [0.73 ]\n",
            " [0.73 ]\n",
            " [0.73 ]\n",
            " [0.73 ]\n",
            " [0.73 ]\n",
            " [0.73 ]\n",
            " [0.73 ]\n",
            " [0.73 ]\n",
            " [0.73 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [1.   ]\n",
            " [1.   ]\n",
            " [1.   ]\n",
            " [1.   ]\n",
            " [1.   ]\n",
            " [1.   ]\n",
            " [1.   ]\n",
            " [1.   ]\n",
            " [1.   ]\n",
            " [1.   ]\n",
            " [1.   ]\n",
            " [0.45 ]\n",
            " [0.45 ]\n",
            " [0.45 ]\n",
            " [0.45 ]\n",
            " [0.45 ]\n",
            " [0.45 ]\n",
            " [0.45 ]\n",
            " [0.45 ]\n",
            " [0.45 ]\n",
            " [0.45 ]\n",
            " [0.45 ]\n",
            " [0.73 ]\n",
            " [0.73 ]\n",
            " [0.73 ]\n",
            " [0.73 ]\n",
            " [0.73 ]\n",
            " [0.73 ]\n",
            " [0.73 ]\n",
            " [0.73 ]\n",
            " [0.73 ]\n",
            " [0.73 ]\n",
            " [0.73 ]\n",
            " [0.9  ]\n",
            " [0.9  ]\n",
            " [0.9  ]\n",
            " [0.9  ]\n",
            " [0.9  ]\n",
            " [0.9  ]\n",
            " [0.9  ]\n",
            " [0.9  ]\n",
            " [0.9  ]\n",
            " [0.9  ]\n",
            " [0.9  ]\n",
            " [0.35 ]\n",
            " [0.35 ]\n",
            " [0.35 ]\n",
            " [0.35 ]\n",
            " [0.35 ]\n",
            " [0.35 ]\n",
            " [0.35 ]\n",
            " [0.35 ]\n",
            " [0.35 ]\n",
            " [0.35 ]\n",
            " [0.35 ]\n",
            " [0.   ]\n",
            " [0.   ]\n",
            " [0.   ]\n",
            " [0.   ]\n",
            " [0.   ]\n",
            " [0.   ]\n",
            " [0.   ]\n",
            " [0.   ]\n",
            " [0.   ]\n",
            " [0.   ]\n",
            " [0.   ]\n",
            " [0.6  ]\n",
            " [0.6  ]\n",
            " [0.6  ]\n",
            " [0.6  ]\n",
            " [0.6  ]\n",
            " [0.6  ]\n",
            " [0.6  ]\n",
            " [0.6  ]\n",
            " [0.6  ]\n",
            " [0.6  ]\n",
            " [0.6  ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [0.15 ]\n",
            " [1.   ]\n",
            " [1.   ]\n",
            " [1.   ]\n",
            " [1.   ]\n",
            " [1.   ]\n",
            " [1.   ]\n",
            " [1.   ]\n",
            " [1.   ]\n",
            " [1.   ]\n",
            " [1.   ]\n",
            " [1.   ]\n",
            " [0.85 ]\n",
            " [0.85 ]\n",
            " [0.85 ]\n",
            " [0.85 ]\n",
            " [0.85 ]\n",
            " [0.85 ]\n",
            " [0.85 ]\n",
            " [0.85 ]\n",
            " [0.85 ]\n",
            " [0.85 ]\n",
            " [0.85 ]\n",
            " [0.65 ]\n",
            " [0.65 ]\n",
            " [0.65 ]\n",
            " [0.65 ]\n",
            " [0.65 ]\n",
            " [0.65 ]\n",
            " [0.65 ]\n",
            " [0.65 ]\n",
            " [0.65 ]\n",
            " [0.65 ]\n",
            " [0.65 ]\n",
            " [0.775]\n",
            " [0.775]\n",
            " [0.775]\n",
            " [0.775]\n",
            " [0.775]\n",
            " [0.775]\n",
            " [0.775]\n",
            " [0.775]\n",
            " [0.775]\n",
            " [0.775]\n",
            " [0.775]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Format the input data to a shape which can be accepted by the model"
      ],
      "metadata": {
        "id": "cYQ7ZDOZH9W6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "x = np.array(x).reshape((187, 6, 1))\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k36CS96WPWbk",
        "outputId": "11708df8-8f95-42f9-9a75-e66fb92d5d5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(187, 6, 1)\n",
            "(187, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get train, test and validation split\n"
      ],
      "metadata": {
        "id": "nz-lvH3wQEvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train_cv, x_test, y_train_cv, y_test = train_test_split(x, y, test_size=0.20, random_state=50)\n",
        "x_train, x_cv, y_train, y_cv = train_test_split(x_train_cv, y_train_cv, test_size=0.25, random_state=25)"
      ],
      "metadata": {
        "id": "IjcGW7o8QEej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train = np.array(x_train).reshape((111, ))\n",
        "# x_test = np.array(x_test).reshape((38, 1, 6))\n",
        "# x_cv = np.array(x_cv).reshape((38, 1, 6))\n",
        "print(x_train.shape, x_test.shape, x_cv.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7NZtp3ZRGQ6",
        "outputId": "6458bb36-7407-4748-b8f9-ad7a1317c832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(111, 6, 1) (38, 6, 1) (38, 6, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape, y_test.shape, y_cv.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r0hvzwDQX-M",
        "outputId": "74d3fb81-7032-46f2-eb9f-78fb319cba74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(111, 1) (38, 1) (38, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining parameters for model"
      ],
      "metadata": {
        "id": "9s5qiUCkSglA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 200\n",
        "batch_size = 1"
      ],
      "metadata": {
        "id": "F0QZRpIjSRmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model design import statements"
      ],
      "metadata": {
        "id": "sxRNhW8a9WJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.layers import InputLayer, GRU, BatchNormalization, Conv1D, MaxPooling1D, Bidirectional, Dense, Flatten, PReLU, LSTM, ReLU, LeakyReLU, Add, Masking\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Model, Input\n",
        "import keras "
      ],
      "metadata": {
        "id": "Z1FO2y2i9V4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model design "
      ],
      "metadata": {
        "id": "qpKavfL7-8uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model design using functional mode \n",
        "# input layer \n",
        "input = Input(shape=(6, 1))\n",
        "# First convolutional block\n",
        "x1 = Conv1D(filters=30, kernel_size=3, padding='causal', activation='ReLU')(input)\n",
        "x2 = LeakyReLU()(x1)\n",
        "x3 = MaxPooling1D(pool_size=1)(x2)\n",
        "x4 = BatchNormalization()(x3)\n",
        "\n",
        "# second convolutional block\n",
        "x5 = Conv1D(filters=30, kernel_size=3, padding='causal', activation='ReLU')(x4)\n",
        "x6 = ReLU()(x5)\n",
        "x7 = MaxPooling1D(pool_size=1)(x6)\n",
        "x8 = BatchNormalization()(x7)\n",
        "\n",
        "# First GRU layer with batchnorm\n",
        "x9 = Bidirectional(GRU(30, activation='sigmoid', return_sequences=True, dropout=0.3))(x8)\n",
        "x10 = BatchNormalization()(x9)\n",
        "\n",
        "# second GRU layer\n",
        "x11 = Bidirectional(GRU(60, activation='sigmoid', return_sequences=False, dropout=0.3))(x10)\n",
        "x12 = Add()([x11, input]) # skip connection\n",
        "\n",
        "# third GRU layer \n",
        "x13 = Bidirectional(GRU(100, activation='sigmoid', return_sequences=False, dropout=0.5))(x12)\n",
        "\n",
        "# first dense layer with batchnorm\n",
        "x14 = Dense(30, activation='tanh')(x13)\n",
        "x15 = Add()([x14, input]) # skip connection \n",
        "x16 = BatchNormalization()(x15)\n",
        "\n",
        "# output layer \n",
        "x17 = Dense(1, activation='linear')(x16)\n",
        "lrcn_model = Model(input, x17)\n",
        "\n",
        "# model summary \n",
        "lrcn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7Rl96enGRLr",
        "outputId": "d0c24c26-849f-42f1-b77f-6b58a86042c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 6, 1)]       0           []                               \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 6, 30)        120         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 6, 30)        0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 6, 30)        0           ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 6, 30)       120         ['max_pooling1d[0][0]']          \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 6, 30)        2730        ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)                 (None, 6, 30)        0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPooling1D)  (None, 6, 30)       0           ['re_lu_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 6, 30)       120         ['max_pooling1d_1[0][0]']        \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 6, 60)        11160       ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 6, 60)       240         ['bidirectional[0][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 120)         43920       ['batch_normalization_2[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 6, 120)       0           ['bidirectional_1[0][0]',        \n",
            "                                                                  'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirectional  (None, 200)         133200      ['add[0][0]']                    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 30)           6030        ['bidirectional_2[0][0]']        \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 6, 30)        0           ['dense[0][0]',                  \n",
            "                                                                  'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 6, 30)       120         ['add_1[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 6, 1)         31          ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 197,791\n",
            "Trainable params: 197,491\n",
            "Non-trainable params: 300\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lrcn_model.compile(optimizer='Adam', loss=tensorflow.keras.losses.MeanSquaredError(), metrics=[tensorflow.keras.metrics.RootMeanSquaredError(), tensorflow.keras.metrics.MeanAbsoluteError()])"
      ],
      "metadata": {
        "id": "Gpwbe8bEHIfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "details = lrcn_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_cv, y_cv))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l43J5hcDHhDR",
        "outputId": "f4713e69-0213-4e81-d298-3d6b96fbae53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "111/111 [==============================] - 11s 26ms/step - loss: 9633.1445 - root_mean_squared_error: 98.1486 - mean_absolute_error: 98.1453 - val_loss: 10966.1377 - val_root_mean_squared_error: 104.7193 - val_mean_absolute_error: 104.7176\n",
            "Epoch 2/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 9199.6123 - root_mean_squared_error: 95.9146 - mean_absolute_error: 95.9073 - val_loss: 10024.3652 - val_root_mean_squared_error: 100.1218 - val_mean_absolute_error: 100.1200\n",
            "Epoch 3/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 8448.1689 - root_mean_squared_error: 91.9139 - mean_absolute_error: 91.9006 - val_loss: 8653.6328 - val_root_mean_squared_error: 93.0249 - val_mean_absolute_error: 93.0230\n",
            "Epoch 4/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 7435.3965 - root_mean_squared_error: 86.2288 - mean_absolute_error: 86.2070 - val_loss: 7190.0190 - val_root_mean_squared_error: 84.7940 - val_mean_absolute_error: 84.7919\n",
            "Epoch 5/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 6255.1133 - root_mean_squared_error: 79.0893 - mean_absolute_error: 79.0539 - val_loss: 5773.7627 - val_root_mean_squared_error: 75.9853 - val_mean_absolute_error: 75.9830\n",
            "Epoch 6/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 5012.7217 - root_mean_squared_error: 70.8006 - mean_absolute_error: 70.7515 - val_loss: 4454.2041 - val_root_mean_squared_error: 66.7398 - val_mean_absolute_error: 66.7372\n",
            "Epoch 7/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 3809.4390 - root_mean_squared_error: 61.7206 - mean_absolute_error: 61.6599 - val_loss: 3270.2427 - val_root_mean_squared_error: 57.1860 - val_mean_absolute_error: 57.1829\n",
            "Epoch 8/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 2729.6833 - root_mean_squared_error: 52.2464 - mean_absolute_error: 52.1753 - val_loss: 2262.6453 - val_root_mean_squared_error: 47.5673 - val_mean_absolute_error: 47.5635\n",
            "Epoch 9/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 1832.2277 - root_mean_squared_error: 42.8045 - mean_absolute_error: 42.7042 - val_loss: 1462.4772 - val_root_mean_squared_error: 38.2424 - val_mean_absolute_error: 38.2377\n",
            "Epoch 10/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 1143.3107 - root_mean_squared_error: 33.8129 - mean_absolute_error: 33.7163 - val_loss: 876.1504 - val_root_mean_squared_error: 29.5998 - val_mean_absolute_error: 29.5938\n",
            "Epoch 11/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 658.1232 - root_mean_squared_error: 25.6539 - mean_absolute_error: 25.5595 - val_loss: 482.6537 - val_root_mean_squared_error: 21.9694 - val_mean_absolute_error: 21.9613\n",
            "Epoch 12/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 347.1292 - root_mean_squared_error: 18.6314 - mean_absolute_error: 18.5295 - val_loss: 242.9523 - val_root_mean_squared_error: 15.5869 - val_mean_absolute_error: 15.5755\n",
            "Epoch 13/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 166.9315 - root_mean_squared_error: 12.9202 - mean_absolute_error: 12.8227 - val_loss: 111.5909 - val_root_mean_squared_error: 10.5637 - val_mean_absolute_error: 10.5469\n",
            "Epoch 14/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 73.0015 - root_mean_squared_error: 8.5441 - mean_absolute_error: 8.4710 - val_loss: 47.0525 - val_root_mean_squared_error: 6.8595 - val_mean_absolute_error: 6.8336\n",
            "Epoch 15/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 29.0995 - root_mean_squared_error: 5.3944 - mean_absolute_error: 5.3162 - val_loss: 18.3259 - val_root_mean_squared_error: 4.2809 - val_mean_absolute_error: 4.2393\n",
            "Epoch 16/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 10.7059 - root_mean_squared_error: 3.2720 - mean_absolute_error: 3.1739 - val_loss: 6.6958 - val_root_mean_squared_error: 2.5876 - val_mean_absolute_error: 2.5181\n",
            "Epoch 17/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 3.7744 - root_mean_squared_error: 1.9428 - mean_absolute_error: 1.8059 - val_loss: 2.5073 - val_root_mean_squared_error: 1.5834 - val_mean_absolute_error: 1.4672\n",
            "Epoch 18/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 1.4167 - root_mean_squared_error: 1.1903 - mean_absolute_error: 1.0239 - val_loss: 1.0786 - val_root_mean_squared_error: 1.0385 - val_mean_absolute_error: 0.9052\n",
            "Epoch 19/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.6869 - root_mean_squared_error: 0.8288 - mean_absolute_error: 0.7254 - val_loss: 0.6129 - val_root_mean_squared_error: 0.7829 - val_mean_absolute_error: 0.6812\n",
            "Epoch 20/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4837 - root_mean_squared_error: 0.6955 - mean_absolute_error: 0.6191 - val_loss: 0.4536 - val_root_mean_squared_error: 0.6735 - val_mean_absolute_error: 0.5854\n",
            "Epoch 21/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4361 - root_mean_squared_error: 0.6604 - mean_absolute_error: 0.5853 - val_loss: 0.4080 - val_root_mean_squared_error: 0.6388 - val_mean_absolute_error: 0.5502\n",
            "Epoch 22/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4253 - root_mean_squared_error: 0.6522 - mean_absolute_error: 0.5723 - val_loss: 0.3985 - val_root_mean_squared_error: 0.6312 - val_mean_absolute_error: 0.5411\n",
            "Epoch 23/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4228 - root_mean_squared_error: 0.6503 - mean_absolute_error: 0.5648 - val_loss: 0.3864 - val_root_mean_squared_error: 0.6216 - val_mean_absolute_error: 0.5280\n",
            "Epoch 24/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4202 - root_mean_squared_error: 0.6483 - mean_absolute_error: 0.5606 - val_loss: 0.3772 - val_root_mean_squared_error: 0.6142 - val_mean_absolute_error: 0.5197\n",
            "Epoch 25/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4195 - root_mean_squared_error: 0.6477 - mean_absolute_error: 0.5611 - val_loss: 0.3802 - val_root_mean_squared_error: 0.6166 - val_mean_absolute_error: 0.5223\n",
            "Epoch 26/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4203 - root_mean_squared_error: 0.6483 - mean_absolute_error: 0.5594 - val_loss: 0.3756 - val_root_mean_squared_error: 0.6129 - val_mean_absolute_error: 0.5183\n",
            "Epoch 27/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4205 - root_mean_squared_error: 0.6485 - mean_absolute_error: 0.5592 - val_loss: 0.3758 - val_root_mean_squared_error: 0.6130 - val_mean_absolute_error: 0.5190\n",
            "Epoch 28/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4226 - root_mean_squared_error: 0.6501 - mean_absolute_error: 0.5643 - val_loss: 0.3695 - val_root_mean_squared_error: 0.6079 - val_mean_absolute_error: 0.5123\n",
            "Epoch 29/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4229 - root_mean_squared_error: 0.6503 - mean_absolute_error: 0.5579 - val_loss: 0.3828 - val_root_mean_squared_error: 0.6187 - val_mean_absolute_error: 0.5244\n",
            "Epoch 30/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4211 - root_mean_squared_error: 0.6489 - mean_absolute_error: 0.5542 - val_loss: 0.3804 - val_root_mean_squared_error: 0.6168 - val_mean_absolute_error: 0.5224\n",
            "Epoch 31/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4242 - root_mean_squared_error: 0.6513 - mean_absolute_error: 0.5652 - val_loss: 0.3826 - val_root_mean_squared_error: 0.6185 - val_mean_absolute_error: 0.5242\n",
            "Epoch 32/200\n",
            "111/111 [==============================] - 2s 19ms/step - loss: 0.4242 - root_mean_squared_error: 0.6513 - mean_absolute_error: 0.5610 - val_loss: 0.3837 - val_root_mean_squared_error: 0.6194 - val_mean_absolute_error: 0.5252\n",
            "Epoch 33/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4200 - root_mean_squared_error: 0.6481 - mean_absolute_error: 0.5651 - val_loss: 0.3746 - val_root_mean_squared_error: 0.6121 - val_mean_absolute_error: 0.5175\n",
            "Epoch 34/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4249 - root_mean_squared_error: 0.6518 - mean_absolute_error: 0.5619 - val_loss: 0.3691 - val_root_mean_squared_error: 0.6075 - val_mean_absolute_error: 0.5118\n",
            "Epoch 35/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4208 - root_mean_squared_error: 0.6487 - mean_absolute_error: 0.5602 - val_loss: 0.3726 - val_root_mean_squared_error: 0.6104 - val_mean_absolute_error: 0.5154\n",
            "Epoch 36/200\n",
            "111/111 [==============================] - 3s 25ms/step - loss: 0.4234 - root_mean_squared_error: 0.6507 - mean_absolute_error: 0.5582 - val_loss: 0.3723 - val_root_mean_squared_error: 0.6102 - val_mean_absolute_error: 0.5151\n",
            "Epoch 37/200\n",
            "111/111 [==============================] - 3s 23ms/step - loss: 0.4217 - root_mean_squared_error: 0.6494 - mean_absolute_error: 0.5613 - val_loss: 0.3778 - val_root_mean_squared_error: 0.6147 - val_mean_absolute_error: 0.5202\n",
            "Epoch 38/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4222 - root_mean_squared_error: 0.6498 - mean_absolute_error: 0.5593 - val_loss: 0.3725 - val_root_mean_squared_error: 0.6103 - val_mean_absolute_error: 0.5153\n",
            "Epoch 39/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4205 - root_mean_squared_error: 0.6485 - mean_absolute_error: 0.5565 - val_loss: 0.3914 - val_root_mean_squared_error: 0.6256 - val_mean_absolute_error: 0.5337\n",
            "Epoch 40/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4291 - root_mean_squared_error: 0.6551 - mean_absolute_error: 0.5684 - val_loss: 0.3840 - val_root_mean_squared_error: 0.6196 - val_mean_absolute_error: 0.5253\n",
            "Epoch 41/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4247 - root_mean_squared_error: 0.6517 - mean_absolute_error: 0.5590 - val_loss: 0.3830 - val_root_mean_squared_error: 0.6189 - val_mean_absolute_error: 0.5244\n",
            "Epoch 42/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4229 - root_mean_squared_error: 0.6503 - mean_absolute_error: 0.5625 - val_loss: 0.3948 - val_root_mean_squared_error: 0.6283 - val_mean_absolute_error: 0.5374\n",
            "Epoch 43/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4248 - root_mean_squared_error: 0.6518 - mean_absolute_error: 0.5638 - val_loss: 0.3726 - val_root_mean_squared_error: 0.6104 - val_mean_absolute_error: 0.5155\n",
            "Epoch 44/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4233 - root_mean_squared_error: 0.6506 - mean_absolute_error: 0.5574 - val_loss: 0.3819 - val_root_mean_squared_error: 0.6180 - val_mean_absolute_error: 0.5237\n",
            "Epoch 45/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4230 - root_mean_squared_error: 0.6503 - mean_absolute_error: 0.5663 - val_loss: 0.3642 - val_root_mean_squared_error: 0.6035 - val_mean_absolute_error: 0.5058\n",
            "Epoch 46/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4271 - root_mean_squared_error: 0.6535 - mean_absolute_error: 0.5571 - val_loss: 0.3655 - val_root_mean_squared_error: 0.6046 - val_mean_absolute_error: 0.5075\n",
            "Epoch 47/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4285 - root_mean_squared_error: 0.6546 - mean_absolute_error: 0.5670 - val_loss: 0.3739 - val_root_mean_squared_error: 0.6115 - val_mean_absolute_error: 0.5164\n",
            "Epoch 48/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4226 - root_mean_squared_error: 0.6500 - mean_absolute_error: 0.5583 - val_loss: 0.3697 - val_root_mean_squared_error: 0.6080 - val_mean_absolute_error: 0.5124\n",
            "Epoch 49/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4206 - root_mean_squared_error: 0.6486 - mean_absolute_error: 0.5494 - val_loss: 0.4078 - val_root_mean_squared_error: 0.6386 - val_mean_absolute_error: 0.5500\n",
            "Epoch 50/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4204 - root_mean_squared_error: 0.6483 - mean_absolute_error: 0.5721 - val_loss: 0.3577 - val_root_mean_squared_error: 0.5981 - val_mean_absolute_error: 0.4995\n",
            "Epoch 51/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4275 - root_mean_squared_error: 0.6539 - mean_absolute_error: 0.5641 - val_loss: 0.3780 - val_root_mean_squared_error: 0.6148 - val_mean_absolute_error: 0.5205\n",
            "Epoch 52/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4235 - root_mean_squared_error: 0.6508 - mean_absolute_error: 0.5603 - val_loss: 0.4053 - val_root_mean_squared_error: 0.6366 - val_mean_absolute_error: 0.5477\n",
            "Epoch 53/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4318 - root_mean_squared_error: 0.6571 - mean_absolute_error: 0.5680 - val_loss: 0.3718 - val_root_mean_squared_error: 0.6098 - val_mean_absolute_error: 0.5147\n",
            "Epoch 54/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4308 - root_mean_squared_error: 0.6564 - mean_absolute_error: 0.5689 - val_loss: 0.3739 - val_root_mean_squared_error: 0.6115 - val_mean_absolute_error: 0.5167\n",
            "Epoch 55/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4308 - root_mean_squared_error: 0.6564 - mean_absolute_error: 0.5664 - val_loss: 0.3766 - val_root_mean_squared_error: 0.6137 - val_mean_absolute_error: 0.5192\n",
            "Epoch 56/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4315 - root_mean_squared_error: 0.6569 - mean_absolute_error: 0.5619 - val_loss: 0.3956 - val_root_mean_squared_error: 0.6290 - val_mean_absolute_error: 0.5373\n",
            "Epoch 57/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4352 - root_mean_squared_error: 0.6597 - mean_absolute_error: 0.5724 - val_loss: 0.3825 - val_root_mean_squared_error: 0.6185 - val_mean_absolute_error: 0.5241\n",
            "Epoch 58/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4289 - root_mean_squared_error: 0.6549 - mean_absolute_error: 0.5628 - val_loss: 0.3636 - val_root_mean_squared_error: 0.6030 - val_mean_absolute_error: 0.5051\n",
            "Epoch 59/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4217 - root_mean_squared_error: 0.6494 - mean_absolute_error: 0.5547 - val_loss: 0.4165 - val_root_mean_squared_error: 0.6454 - val_mean_absolute_error: 0.5577\n",
            "Epoch 60/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4561 - root_mean_squared_error: 0.6753 - mean_absolute_error: 0.5878 - val_loss: 0.3593 - val_root_mean_squared_error: 0.5994 - val_mean_absolute_error: 0.4995\n",
            "Epoch 61/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4256 - root_mean_squared_error: 0.6524 - mean_absolute_error: 0.5607 - val_loss: 0.4028 - val_root_mean_squared_error: 0.6347 - val_mean_absolute_error: 0.5453\n",
            "Epoch 62/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4311 - root_mean_squared_error: 0.6566 - mean_absolute_error: 0.5672 - val_loss: 0.3791 - val_root_mean_squared_error: 0.6157 - val_mean_absolute_error: 0.5215\n",
            "Epoch 63/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4298 - root_mean_squared_error: 0.6556 - mean_absolute_error: 0.5624 - val_loss: 0.4015 - val_root_mean_squared_error: 0.6336 - val_mean_absolute_error: 0.5441\n",
            "Epoch 64/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4438 - root_mean_squared_error: 0.6662 - mean_absolute_error: 0.5794 - val_loss: 0.3592 - val_root_mean_squared_error: 0.5993 - val_mean_absolute_error: 0.4994\n",
            "Epoch 65/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4337 - root_mean_squared_error: 0.6585 - mean_absolute_error: 0.5602 - val_loss: 0.3679 - val_root_mean_squared_error: 0.6065 - val_mean_absolute_error: 0.5042\n",
            "Epoch 66/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4382 - root_mean_squared_error: 0.6620 - mean_absolute_error: 0.5659 - val_loss: 0.3633 - val_root_mean_squared_error: 0.6028 - val_mean_absolute_error: 0.5049\n",
            "Epoch 67/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4333 - root_mean_squared_error: 0.6583 - mean_absolute_error: 0.5697 - val_loss: 0.3585 - val_root_mean_squared_error: 0.5987 - val_mean_absolute_error: 0.5014\n",
            "Epoch 68/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4341 - root_mean_squared_error: 0.6589 - mean_absolute_error: 0.5638 - val_loss: 0.3930 - val_root_mean_squared_error: 0.6269 - val_mean_absolute_error: 0.5354\n",
            "Epoch 69/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4335 - root_mean_squared_error: 0.6584 - mean_absolute_error: 0.5693 - val_loss: 0.3594 - val_root_mean_squared_error: 0.5995 - val_mean_absolute_error: 0.4995\n",
            "Epoch 70/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4496 - root_mean_squared_error: 0.6705 - mean_absolute_error: 0.5735 - val_loss: 0.3637 - val_root_mean_squared_error: 0.6031 - val_mean_absolute_error: 0.5054\n",
            "Epoch 71/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4573 - root_mean_squared_error: 0.6763 - mean_absolute_error: 0.5777 - val_loss: 0.3825 - val_root_mean_squared_error: 0.6185 - val_mean_absolute_error: 0.5241\n",
            "Epoch 72/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4388 - root_mean_squared_error: 0.6624 - mean_absolute_error: 0.5780 - val_loss: 0.3846 - val_root_mean_squared_error: 0.6202 - val_mean_absolute_error: 0.5260\n",
            "Epoch 73/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4316 - root_mean_squared_error: 0.6569 - mean_absolute_error: 0.5492 - val_loss: 0.6782 - val_root_mean_squared_error: 0.8235 - val_mean_absolute_error: 0.7131\n",
            "Epoch 74/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4389 - root_mean_squared_error: 0.6625 - mean_absolute_error: 0.5746 - val_loss: 0.3565 - val_root_mean_squared_error: 0.5971 - val_mean_absolute_error: 0.5004\n",
            "Epoch 75/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4312 - root_mean_squared_error: 0.6567 - mean_absolute_error: 0.5679 - val_loss: 0.3905 - val_root_mean_squared_error: 0.6249 - val_mean_absolute_error: 0.5327\n",
            "Epoch 76/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4148 - root_mean_squared_error: 0.6440 - mean_absolute_error: 0.5348 - val_loss: 0.3565 - val_root_mean_squared_error: 0.5971 - val_mean_absolute_error: 0.5004\n",
            "Epoch 77/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4284 - root_mean_squared_error: 0.6545 - mean_absolute_error: 0.5664 - val_loss: 0.3626 - val_root_mean_squared_error: 0.6021 - val_mean_absolute_error: 0.5028\n",
            "Epoch 78/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4263 - root_mean_squared_error: 0.6529 - mean_absolute_error: 0.5636 - val_loss: 0.3710 - val_root_mean_squared_error: 0.6091 - val_mean_absolute_error: 0.5048\n",
            "Epoch 79/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4494 - root_mean_squared_error: 0.6703 - mean_absolute_error: 0.5705 - val_loss: 0.3830 - val_root_mean_squared_error: 0.6188 - val_mean_absolute_error: 0.5245\n",
            "Epoch 80/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4804 - root_mean_squared_error: 0.6931 - mean_absolute_error: 0.5953 - val_loss: 0.3563 - val_root_mean_squared_error: 0.5969 - val_mean_absolute_error: 0.5003\n",
            "Epoch 81/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4320 - root_mean_squared_error: 0.6573 - mean_absolute_error: 0.5641 - val_loss: 0.3571 - val_root_mean_squared_error: 0.5976 - val_mean_absolute_error: 0.5007\n",
            "Epoch 82/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4406 - root_mean_squared_error: 0.6637 - mean_absolute_error: 0.5664 - val_loss: 0.3986 - val_root_mean_squared_error: 0.6313 - val_mean_absolute_error: 0.5412\n",
            "Epoch 83/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4453 - root_mean_squared_error: 0.6673 - mean_absolute_error: 0.5778 - val_loss: 0.3832 - val_root_mean_squared_error: 0.6190 - val_mean_absolute_error: 0.5247\n",
            "Epoch 84/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4251 - root_mean_squared_error: 0.6520 - mean_absolute_error: 0.5593 - val_loss: 0.5313 - val_root_mean_squared_error: 0.7289 - val_mean_absolute_error: 0.6349\n",
            "Epoch 85/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4471 - root_mean_squared_error: 0.6687 - mean_absolute_error: 0.5710 - val_loss: 0.5526 - val_root_mean_squared_error: 0.7434 - val_mean_absolute_error: 0.6478\n",
            "Epoch 86/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4204 - root_mean_squared_error: 0.6484 - mean_absolute_error: 0.5394 - val_loss: 0.3666 - val_root_mean_squared_error: 0.6055 - val_mean_absolute_error: 0.5090\n",
            "Epoch 87/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4729 - root_mean_squared_error: 0.6876 - mean_absolute_error: 0.5892 - val_loss: 0.4747 - val_root_mean_squared_error: 0.6890 - val_mean_absolute_error: 0.5988\n",
            "Epoch 88/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4469 - root_mean_squared_error: 0.6685 - mean_absolute_error: 0.5808 - val_loss: 0.4389 - val_root_mean_squared_error: 0.6625 - val_mean_absolute_error: 0.5751\n",
            "Epoch 89/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4365 - root_mean_squared_error: 0.6607 - mean_absolute_error: 0.5665 - val_loss: 0.3900 - val_root_mean_squared_error: 0.6245 - val_mean_absolute_error: 0.5320\n",
            "Epoch 90/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4689 - root_mean_squared_error: 0.6848 - mean_absolute_error: 0.5919 - val_loss: 0.3917 - val_root_mean_squared_error: 0.6259 - val_mean_absolute_error: 0.5340\n",
            "Epoch 91/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4829 - root_mean_squared_error: 0.6949 - mean_absolute_error: 0.6063 - val_loss: 0.3797 - val_root_mean_squared_error: 0.6162 - val_mean_absolute_error: 0.5218\n",
            "Epoch 92/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4642 - root_mean_squared_error: 0.6814 - mean_absolute_error: 0.5865 - val_loss: 0.3549 - val_root_mean_squared_error: 0.5958 - val_mean_absolute_error: 0.4997\n",
            "Epoch 93/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4687 - root_mean_squared_error: 0.6846 - mean_absolute_error: 0.5935 - val_loss: 0.4452 - val_root_mean_squared_error: 0.6672 - val_mean_absolute_error: 0.5797\n",
            "Epoch 94/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4435 - root_mean_squared_error: 0.6659 - mean_absolute_error: 0.5783 - val_loss: 0.3726 - val_root_mean_squared_error: 0.6104 - val_mean_absolute_error: 0.5052\n",
            "Epoch 95/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4333 - root_mean_squared_error: 0.6582 - mean_absolute_error: 0.5522 - val_loss: 0.3577 - val_root_mean_squared_error: 0.5981 - val_mean_absolute_error: 0.5010\n",
            "Epoch 96/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4930 - root_mean_squared_error: 0.7022 - mean_absolute_error: 0.5920 - val_loss: 0.3845 - val_root_mean_squared_error: 0.6201 - val_mean_absolute_error: 0.5258\n",
            "Epoch 97/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4505 - root_mean_squared_error: 0.6712 - mean_absolute_error: 0.5660 - val_loss: 0.4698 - val_root_mean_squared_error: 0.6854 - val_mean_absolute_error: 0.5958\n",
            "Epoch 98/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4839 - root_mean_squared_error: 0.6956 - mean_absolute_error: 0.6038 - val_loss: 0.3710 - val_root_mean_squared_error: 0.6091 - val_mean_absolute_error: 0.5139\n",
            "Epoch 99/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4484 - root_mean_squared_error: 0.6696 - mean_absolute_error: 0.5870 - val_loss: 0.3552 - val_root_mean_squared_error: 0.5960 - val_mean_absolute_error: 0.4995\n",
            "Epoch 100/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4486 - root_mean_squared_error: 0.6697 - mean_absolute_error: 0.5814 - val_loss: 0.3555 - val_root_mean_squared_error: 0.5962 - val_mean_absolute_error: 0.4996\n",
            "Epoch 101/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4518 - root_mean_squared_error: 0.6722 - mean_absolute_error: 0.5822 - val_loss: 0.3567 - val_root_mean_squared_error: 0.5973 - val_mean_absolute_error: 0.5005\n",
            "Epoch 102/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4484 - root_mean_squared_error: 0.6696 - mean_absolute_error: 0.5737 - val_loss: 0.4377 - val_root_mean_squared_error: 0.6616 - val_mean_absolute_error: 0.5743\n",
            "Epoch 103/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4385 - root_mean_squared_error: 0.6622 - mean_absolute_error: 0.5815 - val_loss: 0.3791 - val_root_mean_squared_error: 0.6157 - val_mean_absolute_error: 0.5064\n",
            "Epoch 104/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4333 - root_mean_squared_error: 0.6582 - mean_absolute_error: 0.5700 - val_loss: 0.3563 - val_root_mean_squared_error: 0.5969 - val_mean_absolute_error: 0.5002\n",
            "Epoch 105/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4563 - root_mean_squared_error: 0.6755 - mean_absolute_error: 0.5653 - val_loss: 0.4884 - val_root_mean_squared_error: 0.6988 - val_mean_absolute_error: 0.6069\n",
            "Epoch 106/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4856 - root_mean_squared_error: 0.6968 - mean_absolute_error: 0.5956 - val_loss: 0.3585 - val_root_mean_squared_error: 0.5987 - val_mean_absolute_error: 0.5016\n",
            "Epoch 107/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4519 - root_mean_squared_error: 0.6722 - mean_absolute_error: 0.5755 - val_loss: 0.3617 - val_root_mean_squared_error: 0.6014 - val_mean_absolute_error: 0.5023\n",
            "Epoch 108/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4470 - root_mean_squared_error: 0.6686 - mean_absolute_error: 0.5753 - val_loss: 0.3566 - val_root_mean_squared_error: 0.5971 - val_mean_absolute_error: 0.5004\n",
            "Epoch 109/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4458 - root_mean_squared_error: 0.6677 - mean_absolute_error: 0.5694 - val_loss: 0.3601 - val_root_mean_squared_error: 0.6001 - val_mean_absolute_error: 0.5018\n",
            "Epoch 110/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4453 - root_mean_squared_error: 0.6673 - mean_absolute_error: 0.5805 - val_loss: 0.3577 - val_root_mean_squared_error: 0.5981 - val_mean_absolute_error: 0.5007\n",
            "Epoch 111/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4942 - root_mean_squared_error: 0.7030 - mean_absolute_error: 0.6049 - val_loss: 0.3555 - val_root_mean_squared_error: 0.5962 - val_mean_absolute_error: 0.4995\n",
            "Epoch 112/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4391 - root_mean_squared_error: 0.6626 - mean_absolute_error: 0.5674 - val_loss: 0.3600 - val_root_mean_squared_error: 0.6000 - val_mean_absolute_error: 0.5020\n",
            "Epoch 113/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4440 - root_mean_squared_error: 0.6663 - mean_absolute_error: 0.5805 - val_loss: 0.3547 - val_root_mean_squared_error: 0.5956 - val_mean_absolute_error: 0.4994\n",
            "Epoch 114/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4617 - root_mean_squared_error: 0.6795 - mean_absolute_error: 0.5716 - val_loss: 0.4696 - val_root_mean_squared_error: 0.6853 - val_mean_absolute_error: 0.5957\n",
            "Epoch 115/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4800 - root_mean_squared_error: 0.6928 - mean_absolute_error: 0.5865 - val_loss: 0.3640 - val_root_mean_squared_error: 0.6033 - val_mean_absolute_error: 0.5057\n",
            "Epoch 116/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4452 - root_mean_squared_error: 0.6672 - mean_absolute_error: 0.5701 - val_loss: 0.4150 - val_root_mean_squared_error: 0.6442 - val_mean_absolute_error: 0.5564\n",
            "Epoch 117/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4365 - root_mean_squared_error: 0.6607 - mean_absolute_error: 0.5596 - val_loss: 0.5613 - val_root_mean_squared_error: 0.7492 - val_mean_absolute_error: 0.6530\n",
            "Epoch 118/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4504 - root_mean_squared_error: 0.6711 - mean_absolute_error: 0.5775 - val_loss: 0.3877 - val_root_mean_squared_error: 0.6227 - val_mean_absolute_error: 0.5295\n",
            "Epoch 119/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4699 - root_mean_squared_error: 0.6855 - mean_absolute_error: 0.5807 - val_loss: 0.3988 - val_root_mean_squared_error: 0.6315 - val_mean_absolute_error: 0.5414\n",
            "Epoch 120/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4533 - root_mean_squared_error: 0.6733 - mean_absolute_error: 0.5772 - val_loss: 0.4520 - val_root_mean_squared_error: 0.6723 - val_mean_absolute_error: 0.5841\n",
            "Epoch 121/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4450 - root_mean_squared_error: 0.6671 - mean_absolute_error: 0.5711 - val_loss: 0.3789 - val_root_mean_squared_error: 0.6155 - val_mean_absolute_error: 0.5212\n",
            "Epoch 122/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4709 - root_mean_squared_error: 0.6862 - mean_absolute_error: 0.5840 - val_loss: 0.3749 - val_root_mean_squared_error: 0.6123 - val_mean_absolute_error: 0.5176\n",
            "Epoch 123/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4699 - root_mean_squared_error: 0.6855 - mean_absolute_error: 0.5847 - val_loss: 0.3603 - val_root_mean_squared_error: 0.6002 - val_mean_absolute_error: 0.5020\n",
            "Epoch 124/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4176 - root_mean_squared_error: 0.6462 - mean_absolute_error: 0.5479 - val_loss: 0.8151 - val_root_mean_squared_error: 0.9028 - val_mean_absolute_error: 0.7874\n",
            "Epoch 125/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.5282 - root_mean_squared_error: 0.7268 - mean_absolute_error: 0.6143 - val_loss: 0.3699 - val_root_mean_squared_error: 0.6082 - val_mean_absolute_error: 0.5127\n",
            "Epoch 126/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4599 - root_mean_squared_error: 0.6782 - mean_absolute_error: 0.5826 - val_loss: 0.3869 - val_root_mean_squared_error: 0.6220 - val_mean_absolute_error: 0.5286\n",
            "Epoch 127/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4520 - root_mean_squared_error: 0.6723 - mean_absolute_error: 0.5731 - val_loss: 0.4279 - val_root_mean_squared_error: 0.6542 - val_mean_absolute_error: 0.5669\n",
            "Epoch 128/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4354 - root_mean_squared_error: 0.6599 - mean_absolute_error: 0.5743 - val_loss: 0.3589 - val_root_mean_squared_error: 0.5990 - val_mean_absolute_error: 0.4995\n",
            "Epoch 129/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4438 - root_mean_squared_error: 0.6662 - mean_absolute_error: 0.5736 - val_loss: 0.3741 - val_root_mean_squared_error: 0.6117 - val_mean_absolute_error: 0.5169\n",
            "Epoch 130/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4770 - root_mean_squared_error: 0.6907 - mean_absolute_error: 0.5839 - val_loss: 0.5068 - val_root_mean_squared_error: 0.7119 - val_mean_absolute_error: 0.6190\n",
            "Epoch 131/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4516 - root_mean_squared_error: 0.6720 - mean_absolute_error: 0.5767 - val_loss: 0.3679 - val_root_mean_squared_error: 0.6066 - val_mean_absolute_error: 0.5106\n",
            "Epoch 132/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4858 - root_mean_squared_error: 0.6970 - mean_absolute_error: 0.5904 - val_loss: 0.5990 - val_root_mean_squared_error: 0.7740 - val_mean_absolute_error: 0.6738\n",
            "Epoch 133/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4523 - root_mean_squared_error: 0.6725 - mean_absolute_error: 0.5663 - val_loss: 0.4884 - val_root_mean_squared_error: 0.6988 - val_mean_absolute_error: 0.6069\n",
            "Epoch 134/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4609 - root_mean_squared_error: 0.6789 - mean_absolute_error: 0.5728 - val_loss: 0.3620 - val_root_mean_squared_error: 0.6017 - val_mean_absolute_error: 0.5026\n",
            "Epoch 135/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4515 - root_mean_squared_error: 0.6719 - mean_absolute_error: 0.5676 - val_loss: 0.5464 - val_root_mean_squared_error: 0.7392 - val_mean_absolute_error: 0.6441\n",
            "Epoch 136/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4360 - root_mean_squared_error: 0.6603 - mean_absolute_error: 0.5730 - val_loss: 0.3748 - val_root_mean_squared_error: 0.6122 - val_mean_absolute_error: 0.5175\n",
            "Epoch 137/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4433 - root_mean_squared_error: 0.6658 - mean_absolute_error: 0.5706 - val_loss: 0.6268 - val_root_mean_squared_error: 0.7917 - val_mean_absolute_error: 0.6882\n",
            "Epoch 138/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4443 - root_mean_squared_error: 0.6666 - mean_absolute_error: 0.5654 - val_loss: 0.3582 - val_root_mean_squared_error: 0.5985 - val_mean_absolute_error: 0.5013\n",
            "Epoch 139/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4844 - root_mean_squared_error: 0.6960 - mean_absolute_error: 0.5997 - val_loss: 0.4368 - val_root_mean_squared_error: 0.6609 - val_mean_absolute_error: 0.5736\n",
            "Epoch 140/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4404 - root_mean_squared_error: 0.6636 - mean_absolute_error: 0.5770 - val_loss: 0.3661 - val_root_mean_squared_error: 0.6051 - val_mean_absolute_error: 0.5063\n",
            "Epoch 141/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4422 - root_mean_squared_error: 0.6650 - mean_absolute_error: 0.5588 - val_loss: 0.6743 - val_root_mean_squared_error: 0.8212 - val_mean_absolute_error: 0.7113\n",
            "Epoch 142/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4669 - root_mean_squared_error: 0.6833 - mean_absolute_error: 0.5860 - val_loss: 0.3737 - val_root_mean_squared_error: 0.6113 - val_mean_absolute_error: 0.5165\n",
            "Epoch 143/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4577 - root_mean_squared_error: 0.6765 - mean_absolute_error: 0.5806 - val_loss: 0.4057 - val_root_mean_squared_error: 0.6369 - val_mean_absolute_error: 0.5481\n",
            "Epoch 144/200\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 0.4487 - root_mean_squared_error: 0.6699 - mean_absolute_error: 0.5836 - val_loss: 0.3635 - val_root_mean_squared_error: 0.6029 - val_mean_absolute_error: 0.5050\n",
            "Epoch 145/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4751 - root_mean_squared_error: 0.6893 - mean_absolute_error: 0.5833 - val_loss: 0.3600 - val_root_mean_squared_error: 0.6000 - val_mean_absolute_error: 0.4996\n",
            "Epoch 146/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4865 - root_mean_squared_error: 0.6975 - mean_absolute_error: 0.5861 - val_loss: 0.4351 - val_root_mean_squared_error: 0.6596 - val_mean_absolute_error: 0.5725\n",
            "Epoch 147/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4501 - root_mean_squared_error: 0.6709 - mean_absolute_error: 0.5729 - val_loss: 0.4742 - val_root_mean_squared_error: 0.6886 - val_mean_absolute_error: 0.5985\n",
            "Epoch 148/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4548 - root_mean_squared_error: 0.6744 - mean_absolute_error: 0.5848 - val_loss: 0.3700 - val_root_mean_squared_error: 0.6082 - val_mean_absolute_error: 0.5128\n",
            "Epoch 149/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4608 - root_mean_squared_error: 0.6788 - mean_absolute_error: 0.5834 - val_loss: 0.3561 - val_root_mean_squared_error: 0.5967 - val_mean_absolute_error: 0.5001\n",
            "Epoch 150/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4377 - root_mean_squared_error: 0.6616 - mean_absolute_error: 0.5659 - val_loss: 0.4720 - val_root_mean_squared_error: 0.6870 - val_mean_absolute_error: 0.5972\n",
            "Epoch 151/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4412 - root_mean_squared_error: 0.6642 - mean_absolute_error: 0.5730 - val_loss: 0.4996 - val_root_mean_squared_error: 0.7068 - val_mean_absolute_error: 0.6141\n",
            "Epoch 152/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4365 - root_mean_squared_error: 0.6607 - mean_absolute_error: 0.5664 - val_loss: 0.3660 - val_root_mean_squared_error: 0.6050 - val_mean_absolute_error: 0.5083\n",
            "Epoch 153/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4447 - root_mean_squared_error: 0.6668 - mean_absolute_error: 0.5749 - val_loss: 0.4664 - val_root_mean_squared_error: 0.6829 - val_mean_absolute_error: 0.5937\n",
            "Epoch 154/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4490 - root_mean_squared_error: 0.6701 - mean_absolute_error: 0.5741 - val_loss: 0.4058 - val_root_mean_squared_error: 0.6370 - val_mean_absolute_error: 0.5483\n",
            "Epoch 155/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4389 - root_mean_squared_error: 0.6625 - mean_absolute_error: 0.5690 - val_loss: 0.3606 - val_root_mean_squared_error: 0.6005 - val_mean_absolute_error: 0.5006\n",
            "Epoch 156/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4794 - root_mean_squared_error: 0.6924 - mean_absolute_error: 0.5803 - val_loss: 0.3808 - val_root_mean_squared_error: 0.6171 - val_mean_absolute_error: 0.5066\n",
            "Epoch 157/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4458 - root_mean_squared_error: 0.6677 - mean_absolute_error: 0.5695 - val_loss: 0.4248 - val_root_mean_squared_error: 0.6518 - val_mean_absolute_error: 0.5645\n",
            "Epoch 158/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4498 - root_mean_squared_error: 0.6707 - mean_absolute_error: 0.5849 - val_loss: 0.4562 - val_root_mean_squared_error: 0.6754 - val_mean_absolute_error: 0.5871\n",
            "Epoch 159/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4453 - root_mean_squared_error: 0.6673 - mean_absolute_error: 0.5765 - val_loss: 0.4793 - val_root_mean_squared_error: 0.6923 - val_mean_absolute_error: 0.6016\n",
            "Epoch 160/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4411 - root_mean_squared_error: 0.6642 - mean_absolute_error: 0.5763 - val_loss: 0.3914 - val_root_mean_squared_error: 0.6256 - val_mean_absolute_error: 0.5088\n",
            "Epoch 161/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.5310 - root_mean_squared_error: 0.7287 - mean_absolute_error: 0.6177 - val_loss: 0.4085 - val_root_mean_squared_error: 0.6391 - val_mean_absolute_error: 0.5173\n",
            "Epoch 162/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4769 - root_mean_squared_error: 0.6906 - mean_absolute_error: 0.5772 - val_loss: 0.3611 - val_root_mean_squared_error: 0.6009 - val_mean_absolute_error: 0.5013\n",
            "Epoch 163/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4586 - root_mean_squared_error: 0.6772 - mean_absolute_error: 0.5816 - val_loss: 0.4389 - val_root_mean_squared_error: 0.6625 - val_mean_absolute_error: 0.5752\n",
            "Epoch 164/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4598 - root_mean_squared_error: 0.6781 - mean_absolute_error: 0.5781 - val_loss: 0.3959 - val_root_mean_squared_error: 0.6292 - val_mean_absolute_error: 0.5385\n",
            "Epoch 165/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4791 - root_mean_squared_error: 0.6922 - mean_absolute_error: 0.6095 - val_loss: 0.3547 - val_root_mean_squared_error: 0.5955 - val_mean_absolute_error: 0.4995\n",
            "Epoch 166/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4883 - root_mean_squared_error: 0.6988 - mean_absolute_error: 0.6055 - val_loss: 0.3553 - val_root_mean_squared_error: 0.5960 - val_mean_absolute_error: 0.4995\n",
            "Epoch 167/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4567 - root_mean_squared_error: 0.6758 - mean_absolute_error: 0.5825 - val_loss: 0.4466 - val_root_mean_squared_error: 0.6683 - val_mean_absolute_error: 0.5807\n",
            "Epoch 168/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4532 - root_mean_squared_error: 0.6732 - mean_absolute_error: 0.5806 - val_loss: 0.3872 - val_root_mean_squared_error: 0.6223 - val_mean_absolute_error: 0.5289\n",
            "Epoch 169/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4574 - root_mean_squared_error: 0.6763 - mean_absolute_error: 0.5855 - val_loss: 0.6321 - val_root_mean_squared_error: 0.7950 - val_mean_absolute_error: 0.6908\n",
            "Epoch 170/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4566 - root_mean_squared_error: 0.6757 - mean_absolute_error: 0.5771 - val_loss: 0.4338 - val_root_mean_squared_error: 0.6586 - val_mean_absolute_error: 0.5714\n",
            "Epoch 171/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4867 - root_mean_squared_error: 0.6976 - mean_absolute_error: 0.6044 - val_loss: 0.4458 - val_root_mean_squared_error: 0.6677 - val_mean_absolute_error: 0.5801\n",
            "Epoch 172/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4521 - root_mean_squared_error: 0.6724 - mean_absolute_error: 0.5840 - val_loss: 0.3652 - val_root_mean_squared_error: 0.6043 - val_mean_absolute_error: 0.5071\n",
            "Epoch 173/200\n",
            "111/111 [==============================] - 2s 16ms/step - loss: 0.4613 - root_mean_squared_error: 0.6792 - mean_absolute_error: 0.5805 - val_loss: 0.3578 - val_root_mean_squared_error: 0.5982 - val_mean_absolute_error: 0.4995\n",
            "Epoch 174/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4865 - root_mean_squared_error: 0.6975 - mean_absolute_error: 0.5885 - val_loss: 0.3608 - val_root_mean_squared_error: 0.6006 - val_mean_absolute_error: 0.5008\n",
            "Epoch 175/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4318 - root_mean_squared_error: 0.6571 - mean_absolute_error: 0.5585 - val_loss: 0.3563 - val_root_mean_squared_error: 0.5969 - val_mean_absolute_error: 0.4996\n",
            "Epoch 176/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4552 - root_mean_squared_error: 0.6747 - mean_absolute_error: 0.5880 - val_loss: 0.4086 - val_root_mean_squared_error: 0.6392 - val_mean_absolute_error: 0.5506\n",
            "Epoch 177/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4370 - root_mean_squared_error: 0.6610 - mean_absolute_error: 0.5522 - val_loss: 0.3638 - val_root_mean_squared_error: 0.6031 - val_mean_absolute_error: 0.5031\n",
            "Epoch 178/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4231 - root_mean_squared_error: 0.6505 - mean_absolute_error: 0.5300 - val_loss: 0.3562 - val_root_mean_squared_error: 0.5968 - val_mean_absolute_error: 0.4995\n",
            "Epoch 179/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4869 - root_mean_squared_error: 0.6978 - mean_absolute_error: 0.5986 - val_loss: 0.3573 - val_root_mean_squared_error: 0.5978 - val_mean_absolute_error: 0.5008\n",
            "Epoch 180/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4583 - root_mean_squared_error: 0.6770 - mean_absolute_error: 0.5709 - val_loss: 0.3828 - val_root_mean_squared_error: 0.6187 - val_mean_absolute_error: 0.5244\n",
            "Epoch 181/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4464 - root_mean_squared_error: 0.6681 - mean_absolute_error: 0.5789 - val_loss: 0.3618 - val_root_mean_squared_error: 0.6015 - val_mean_absolute_error: 0.5027\n",
            "Epoch 182/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4678 - root_mean_squared_error: 0.6840 - mean_absolute_error: 0.5929 - val_loss: 0.3962 - val_root_mean_squared_error: 0.6295 - val_mean_absolute_error: 0.5388\n",
            "Epoch 183/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4561 - root_mean_squared_error: 0.6754 - mean_absolute_error: 0.5793 - val_loss: 0.4123 - val_root_mean_squared_error: 0.6421 - val_mean_absolute_error: 0.5541\n",
            "Epoch 184/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4694 - root_mean_squared_error: 0.6851 - mean_absolute_error: 0.5904 - val_loss: 0.3654 - val_root_mean_squared_error: 0.6045 - val_mean_absolute_error: 0.5074\n",
            "Epoch 185/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4625 - root_mean_squared_error: 0.6801 - mean_absolute_error: 0.5857 - val_loss: 0.4419 - val_root_mean_squared_error: 0.6648 - val_mean_absolute_error: 0.5775\n",
            "Epoch 186/200\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 0.4800 - root_mean_squared_error: 0.6928 - mean_absolute_error: 0.5997 - val_loss: 0.3964 - val_root_mean_squared_error: 0.6296 - val_mean_absolute_error: 0.5390\n",
            "Epoch 187/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4689 - root_mean_squared_error: 0.6848 - mean_absolute_error: 0.5810 - val_loss: 0.4978 - val_root_mean_squared_error: 0.7055 - val_mean_absolute_error: 0.6128\n",
            "Epoch 188/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4542 - root_mean_squared_error: 0.6739 - mean_absolute_error: 0.5885 - val_loss: 0.3700 - val_root_mean_squared_error: 0.6083 - val_mean_absolute_error: 0.5128\n",
            "Epoch 189/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4518 - root_mean_squared_error: 0.6722 - mean_absolute_error: 0.5714 - val_loss: 0.3976 - val_root_mean_squared_error: 0.6306 - val_mean_absolute_error: 0.5401\n",
            "Epoch 190/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4570 - root_mean_squared_error: 0.6760 - mean_absolute_error: 0.5824 - val_loss: 0.4261 - val_root_mean_squared_error: 0.6528 - val_mean_absolute_error: 0.5655\n",
            "Epoch 191/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4829 - root_mean_squared_error: 0.6949 - mean_absolute_error: 0.6002 - val_loss: 0.3931 - val_root_mean_squared_error: 0.6270 - val_mean_absolute_error: 0.5356\n",
            "Epoch 192/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4649 - root_mean_squared_error: 0.6818 - mean_absolute_error: 0.5916 - val_loss: 0.3610 - val_root_mean_squared_error: 0.6009 - val_mean_absolute_error: 0.5012\n",
            "Epoch 193/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4485 - root_mean_squared_error: 0.6697 - mean_absolute_error: 0.5735 - val_loss: 0.3678 - val_root_mean_squared_error: 0.6065 - val_mean_absolute_error: 0.5104\n",
            "Epoch 194/200\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 0.4509 - root_mean_squared_error: 0.6715 - mean_absolute_error: 0.5730 - val_loss: 0.3552 - val_root_mean_squared_error: 0.5960 - val_mean_absolute_error: 0.4995\n",
            "Epoch 195/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4567 - root_mean_squared_error: 0.6758 - mean_absolute_error: 0.5782 - val_loss: 0.3639 - val_root_mean_squared_error: 0.6032 - val_mean_absolute_error: 0.5055\n",
            "Epoch 196/200\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 0.4485 - root_mean_squared_error: 0.6697 - mean_absolute_error: 0.5574 - val_loss: 0.3741 - val_root_mean_squared_error: 0.6116 - val_mean_absolute_error: 0.5170\n",
            "Epoch 197/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4708 - root_mean_squared_error: 0.6862 - mean_absolute_error: 0.5912 - val_loss: 0.3549 - val_root_mean_squared_error: 0.5958 - val_mean_absolute_error: 0.4994\n",
            "Epoch 198/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4418 - root_mean_squared_error: 0.6647 - mean_absolute_error: 0.5642 - val_loss: 0.3635 - val_root_mean_squared_error: 0.6029 - val_mean_absolute_error: 0.5050\n",
            "Epoch 199/200\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 0.4520 - root_mean_squared_error: 0.6723 - mean_absolute_error: 0.5788 - val_loss: 0.4915 - val_root_mean_squared_error: 0.7011 - val_mean_absolute_error: 0.6087\n",
            "Epoch 200/200\n",
            "111/111 [==============================] - 2s 17ms/step - loss: 0.4404 - root_mean_squared_error: 0.6636 - mean_absolute_error: 0.5651 - val_loss: 0.4140 - val_root_mean_squared_error: 0.6434 - val_mean_absolute_error: 0.5555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/gdrive/MyDrive/Intern bp/spo2 model'"
      ],
      "metadata": {
        "id": "zDnjwuGkqZsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lrcn_model.save(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ABdrrtLha2p",
        "outputId": "2a1791b7-7aa2-4eee-f8fe-a10b6d3d33b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as re_lu_6_layer_call_fn, re_lu_6_layer_call_and_return_conditional_losses, re_lu_7_layer_call_fn, re_lu_7_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/Intern bp/spo2 model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/Intern bp/spo2 model/assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f805e37ae90> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f805e37f750> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f805e29ddd0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f805e2a4750> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f805e242f10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f805e29da50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(details.history['val_loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ZRXCARTiVv78",
        "outputId": "8acf8564-7e6b-4dd5-f71c-e809946a713b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAX3ElEQVR4nO3de2yd933f8fdXvEsUqRshO5ISya3WwSnm2NNsB2mDoS58axO5XWs4KGYtMyYUc7dkt85ZgDlIGqzZJVkNpC7cWKscZHE8N52FzZ2rOk7TAbNj2VZ8jSNWtisJskxLsq6WJUrf/XF+pI9ZHlHkIXloPu8XQPA5v+c5h189PDof/n6/5xKZiSSp2ha0ugBJUusZBpIkw0CSZBhIkjAMJElAe6sLmKoVK1bk2rVrW12GJL1vPPXUU29m5sB46963YbB27Vp27NjR6jIk6X0jIl5rtM5hIkmSYSBJMgwkSRgGkiQMA0kShoEkCcNAkkTFwiAzuevRXfzFT4ZaXYokzSmVCoOI4A9/sJvHfvxGq0uRpDmlUmEAsGJxF28ef6fVZUjSnFK9MOjtNAwkaYwKhkEXB4+fbnUZkjSnVC4MltszkKS/oXJhsKK3i8Mnz3Dm7LlWlyJJc0YlwwDg0AmHiiRpRAXDoBPAoSJJqlPBMKj1DN50ElmSRlU3DI7ZM5CkEZULg+VlmOjgCcNAkkZULgx6u9rpal/gMJEk1alcGEQEK3q7HCaSpDqVCwOoHVE05NFEkjRqwjCIiC0R8UZEPF/XtiwitkfErvJ9aWmPiLgrIgYj4tmIuKLuOZvK9rsiYlNd+9+NiOfKc+6KiJjuf+RYXpJCkt7rQnoGfwRcP6btDuDRzFwPPFoeA9wArC9fm4G7oRYewJ3AVcCVwJ0jAVK2+Sd1zxv7s6bdil6vXCpJ9SYMg8z8AXBoTPNGYGtZ3grcVNd+X9Y8DiyJiIuB64DtmXkoMw8D24Hry7q+zHw8MxO4r+61Zszy3k4OnjjNuXM50z9Kkt4XpjpnsDIz95fl14GVZXkVsKduu72l7Xzte8dpH1dEbI6IHRGxY2ho6ncrW9HbxdlzyZG3z0z5NSRpPml6Arn8RT8rf2Jn5j2ZuSEzNwwMDEz5dfp7OgA4esowkCSYehgcKEM8lO8j95HcB6yp2251aTtf++px2mdU30gYvD080z9Kkt4XphoG24CRI4I2AQ/Vtd9ajiq6GjhShpMeAa6NiKVl4vha4JGy7mhEXF2OIrq17rVmTF93O2DPQJJGtE+0QUR8G/j7wIqI2EvtqKDfBR6IiNuA14Cby+YPAzcCg8BJ4NMAmXkoIr4EPFm2+2JmjkxK/1NqRyz1AH9avmbUuz0Dw0CS4ALCIDM/1WDVNeNsm8DtDV5nC7BlnPYdwM9OVMd06nPOQJLeo5JnII8OEzlnIElARcNgUWc7CwIPLZWkopJhsGBB0NfT4TCRJBWVDAOAvu4OJ5AlqahuGPS0c/SUcwaSBFUOA3sGkjSq2mHgnIEkAVUOg552Dy2VpKK6YWDPQJJGVTcMejo4efosZ86ea3UpktRy1Q2D0bOQ7R1IUnXDYPT6RM4bSFJlw6DfK5dK0qjKhoFXLpWkd1U3DLq925kkjahuGPR4tzNJGlHdMOh2zkCSRlQ2DBZ2ttG2ILyngSRR4TCICPq62x0mkiQqHAYAi7s7OOZ5BpJU9TBod85AkjAM7BlIEhUPgz6HiSQJqHgY1OYMHCaSpIqHgcNEkgQVD4O+7naOnx7m3LlsdSmS1FKVDoPF3R1kwvHT9g4kVVtTYRAR/yIiXoiI5yPi2xHRHRHrIuKJiBiMiO9ERGfZtqs8Hizr19a9zudK+8sRcV1z/6QLt7jc4MahIklVN+UwiIhVwD8HNmTmzwJtwC3AV4CvZeZPA4eB28pTbgMOl/avle2IiEvL8z4MXA/8fkS0TbWuyVhcrk/kJLKkqmt2mKgd6ImIdmAhsB/4BeDBsn4rcFNZ3lgeU9ZfExFR2u/PzHcy8xVgELiyybouiD0DSaqZchhk5j7gPwN/TS0EjgBPAW9l5sin615gVVleBewpzx0u2y+vbx/nOe8REZsjYkdE7BgaGppq6aP6vNuZJAHNDRMtpfZX/TrgA8AiasM8MyYz78nMDZm5YWBgoOnXs2cgSTXNDBP9IvBKZg5l5hngu8DHgCVl2AhgNbCvLO8D1gCU9f3Awfr2cZ4zo94NA3sGkqqtmTD4a+DqiFhYxv6vAV4EHgN+rWyzCXioLG8rjynrv5eZWdpvKUcbrQPWAz9soq4LNnqDG3sGkiqufeJNxpeZT0TEg8DTwDDwDHAP8L+B+yPid0rbveUp9wLfjIhB4BC1I4jIzBci4gFqQTIM3J6ZZ6da12R0tS+goy0cJpJUeVMOA4DMvBO4c0zzbsY5GigzTwG/3uB1vgx8uZlapiIivD6RJFHxM5DB6xNJEhgGJQzsGUiqNsOgy3saSFLlw6Cvp52j9gwkVVzlw2CxdzuTJMPACWRJMgxY3N3B8XeGOesNbiRVWOXDoK9ckuL4O/YOJFVX5cPA6xNJkmFQd4MbewaSqssw8DLWkmQY9HnrS0kyDOwZSJJhMDpn4FnIkqrMMLBnIEmGQXdHG51tC+wZSKq0yocBeEkKSTIMMAwkyTAAb30pqfIMA2r3NLBnIKnKDANG7nZmz0BSdRkGOGcgSYYB3u1MkgwDaj0Db3AjqcoMA949C/m4vQNJFWUY8O6VSz0LWVJVGQZ4fSJJaioMImJJRDwYET+OiJci4qMRsSwitkfErvJ9adk2IuKuiBiMiGcj4oq619lUtt8VEZua/UdNVl+P9zSQVG3N9gx+D/g/mfm3gcuAl4A7gEczcz3waHkMcAOwvnxtBu4GiIhlwJ3AVcCVwJ0jATJb7BlIqroph0FE9AMfB+4FyMzTmfkWsBHYWjbbCtxUljcC92XN48CSiLgYuA7YnpmHMvMwsB24fqp1TcXofZDfsWcgqZqa6RmsA4aA/xYRz0TENyJiEbAyM/eXbV4HVpblVcCeuufvLW2N2v+GiNgcETsiYsfQ0FATpb+XPQNJVddMGLQDVwB3Z+blwAneHRICIDMTmLaD9zPznszckJkbBgYGputlDQNJlddMGOwF9mbmE+Xxg9TC4UAZ/qF8f6Os3wesqXv+6tLWqH3WdLW30dm+gKNvO0wkqZqmHAaZ+TqwJyJ+pjRdA7wIbANGjgjaBDxUlrcBt5ajiq4GjpThpEeAayNiaZk4vra0zaq+7naO2jOQVFHtTT7/nwHfiohOYDfwaWoB80BE3Aa8Btxctn0YuBEYBE6WbcnMQxHxJeDJst0XM/NQk3VNWp/3NJBUYU2FQWbuBDaMs+qacbZN4PYGr7MF2NJMLc1a3NNhz0BSZXkGctHX3e6cgaTKMgyK/p4Ow0BSZRkGRV9Phxeqk1RZhkHR39PBkbfPUJvakKRqMQyKvu4OzpxNTp051+pSJGnWGQZFX0/twCqHiiRVkWFQ9JfLWB9xEllSBRkGxejdzgwDSRVkGBT2DCRVmWFQjNztzDkDSVVkGBSjPYOThoGk6jEMipF7Gnh9IklVZBgUHW0LWNTZ5pyBpEoyDOr0eX0iSRVlGNTp6/b6RJKqyTCoM3J9IkmqGsOgTl9PO0ffdgJZUvUYBnX67BlIqijDoI5zBpKqyjCo09/TwbFTw5w95z0NJFWLYVBn5JIUxz3xTFLFGAZ1+spZyM4bSKoaw6COVy6VVFWGQZ0lCzsBeOvt0y2uRJJml2FQZ+nCWs/gLa9cKqliDIM6/SNh4DCRpIoxDOos6SnDRCccJpJULU2HQUS0RcQzEfG/yuN1EfFERAxGxHciorO0d5XHg2X92rrX+Fxpfzkirmu2pqnqbK9dxtqegaSqmY6ewWeAl+oefwX4Wmb+NHAYuK203wYcLu1fK9sREZcCtwAfBq4Hfj8i2qahrilZsrDTOQNJldNUGETEauCXgG+UxwH8AvBg2WQrcFNZ3lgeU9ZfU7bfCNyfme9k5ivAIHBlM3U1o7+ng7dOOkwkqVqa7Rn8V+C3gXPl8XLgrcwcOYV3L7CqLK8C9gCU9UfK9qPt4zxn1i1d1OEwkaTKmXIYRMQvA29k5lPTWM9EP3NzROyIiB1DQ0Mz8jOW9HTaM5BUOc30DD4GfDIiXgXupzY89HvAkohoL9usBvaV5X3AGoCyvh84WN8+znPeIzPvycwNmblhYGCgidIb61/Y4ZyBpMqZchhk5ucyc3VmrqU2Afy9zPwN4DHg18pmm4CHyvK28piy/nuZmaX9lnK00TpgPfDDqdbVrKULa8NEtdIkqRraJ95k0v4tcH9E/A7wDHBvab8X+GZEDAKHqAUImflCRDwAvAgMA7dn5tkZqOuCLOnp5Oy55Pg7wyzu7mhVGZI0q6YlDDLz+8D3y/JuxjkaKDNPAb/e4PlfBr48HbU0q7/ukhSGgaSq8AzkMZb0eH0iSdVjGIyxdJFXLpVUPYbBGCM9g8P2DCRViGEwxsicwRHPNZBUIYbBGKNXLrVnIKlCDIMxvHKppCoyDMaxZGEnhx0mklQhhsE4lnhJCkkVYxiMY9miTg55tzNJFWIYjMMwkFQ1hsE4li/q4uDxd1pdhiTNGsNgHMt7Ozlx+iynzrTsenmSNKsMg3EsL5ekOOhQkaSKMAzGsby3C4BDxw0DSdVgGIxjWekZvHnCeQNJ1WAYjGNFby0M7BlIqgrDYBzLRucM7BlIqgbDYBy9Xe10ti9wAllSZRgG44gIli/q5KDDRJIqwjBoYHmvZyFLqg7DoIFlnoUsqUIMgwZWLOp0zkBSZRgGDSxzzkBShRgGDSzv7eLtM2c5eXq41aVI0owzDBoYvT6RvQNJFWAYNLC814vVSaoOw6CBFeVidUPHPKJI0vxnGDRwUX83AK8fPdXiSiRp5k05DCJiTUQ8FhEvRsQLEfGZ0r4sIrZHxK7yfWlpj4i4KyIGI+LZiLii7rU2le13RcSm5v9ZzVvR20XbguDAEcNA0vzXTM9gGPhXmXkpcDVwe0RcCtwBPJqZ64FHy2OAG4D15WszcDfUwgO4E7gKuBK4cyRAWqltQTDQ22XPQFIlTDkMMnN/Zj5dlo8BLwGrgI3A1rLZVuCmsrwRuC9rHgeWRMTFwHXA9sw8lJmHge3A9VOtazqt7O/mgGEgqQKmZc4gItYClwNPACszc39Z9TqwsiyvAvbUPW1vaWvUPt7P2RwROyJix9DQ0HSUfl4X9XXxusNEkiqg6TCIiF7gj4HPZubR+nWZmUA2+zPqXu+ezNyQmRsGBgam62Ubuqiv22EiSZXQVBhERAe1IPhWZn63NB8owz+U72+U9n3Amrqnry5tjdpb7qL+Ho6dGvYsZEnzXjNHEwVwL/BSZn61btU2YOSIoE3AQ3Xtt5ajiq4GjpThpEeAayNiaZk4vra0tdxF/bVzDRwqkjTftTfx3I8B/xB4LiJ2lrZ/B/wu8EBE3Aa8Btxc1j0M3AgMAieBTwNk5qGI+BLwZNnui5l5qIm6ps3KvnKuwZFTXDLQ2+JqJGnmTDkMMvP/AtFg9TXjbJ/A7Q1eawuwZaq1zJSL+jzxTFI1eAbyeXgWsqSqMAzOY2FnO4u72z0LWdK8ZxhMwMNLJVWBYTCBi/q72W/PQNI8ZxhM4EPLF/LqmyeozX9L0vxkGExg7fJFHD01zOGTZ1pdiiTNGMNgAutWLALglTdPtLgSSZo5hsEE1pYweO2gYSBp/jIMJrBm6UIWBLxqz0DSPGYYTKCzfQGrly7klYMnW12KJM0Yw+ACjBxRJEnzlWFwAdatWOThpZLmNcPgAqxdvohj7wxz8MTpVpciSTPCMLgAI4eXOlQkab4yDC7A+pW1exm8tP/oBFtK0vuTYXABVi3pYUVvJ8/seavVpUjSjDAMLkBE8JE1S9hpGEiapwyDC/SRNUvYPXSCI16jSNI8ZBhcoI+sWQrAj/baO5A0/xgGF+jvrOknAoeKJM1LhsEF6uvu4KcGeg0DSfOSYTAJf2/tMh7ffZC3T59tdSmSNK0Mg0n4xGUXc/L0Wf78pQOtLkWSppVhMAlXrVvOyr4uHtq5r9WlSNK0MgwmoW1B8MnLPsD3Xx7isNcpkjSPGAaTdNPlqxg+l2z9f6+2uhRJmjaGwSR9+AP9fOKyD/D1xwbZdeBYq8uRpGkxZ8IgIq6PiJcjYjAi7mh1Pedz5ycuZVFXO5+5fycHjp5qdTmS1LQ5EQYR0QZ8HbgBuBT4VERc2tqqGlvR28VXb76MV948wS/d9Zd84y938+qbJxg+e67VpUnSlMRcuHtXRHwU+EJmXlcefw4gM/9Do+ds2LAhd+zYMUsVjm/XgWP8mwefHT0RrX1BsKirne6OBXR3tNEW0fjJ51k10eo43+tKmteWLezkgd/86JSeGxFPZeaG8da1N1XV9FkF7Kl7vBe4auxGEbEZ2AzwwQ9+cHYqO4/1KxfzP2//GLuHjvPDVw6x5/BJjp8a5tSZc5waPsu5Bjk7UQCfd23rs1tSCy3unpmP7bkSBhckM+8B7oFaz6DF5Yy6ZKCXSwZ6W12GJE3ZnJgzAPYBa+oery5tkqRZMFfC4ElgfUSsi4hO4BZgW4trkqTKmBPDRJk5HBG/BTwCtAFbMvOFFpclSZUxJ8IAIDMfBh5udR2SVEVzZZhIktRChoEkyTCQJBkGkiTmyOUopiIihoDXpvj0FcCb01jOdLGuyZurtVnX5FjX5E2ltg9l5sB4K963YdCMiNjR6PocrWRdkzdXa7OuybGuyZvu2hwmkiQZBpKk6obBPa0uoAHrmry5Wpt1TY51Td601lbJOQNJ0ntVtWcgSapjGEiSqhUGEXF9RLwcEYMRcUcL61gTEY9FxIsR8UJEfKa0fyEi9kXEzvJ1Y4vqezUinis17ChtyyJie0TsKt+XznJNP1O3X3ZGxNGI+Gwr9llEbImINyLi+bq2cfdP1NxV3nPPRsQVLajtP0XEj8vP/5OIWFLa10bE23X77g9mua6Gv7uI+FzZZy9HxHWzXNd36mp6NSJ2lvbZ3F+NPiNm7n2WmZX4onZp7L8CLgE6gR8Bl7aolouBK8ryYuAnwKXAF4B/PQf21avAijFt/xG4oyzfAXylxb/L14EPtWKfAR8HrgCen2j/ADcCf0rtttZXA0+0oLZrgfay/JW62tbWb9eCusb93ZX/Cz8CuoB15f9t22zVNWb9fwH+fQv2V6PPiBl7n1WpZ3AlMJiZuzPzNHA/sLEVhWTm/sx8uiwfA16idh/ouWwjsLUsbwVuamEt1wB/lZlTPQO9KZn5A+DQmOZG+2cjcF/WPA4siYiLZ7O2zPyzzBwuDx+ndifBWdVgnzWyEbg/M9/JzFeAQWr/f2e1rogI4Gbg2zPxs8/nPJ8RM/Y+q1IYrAL21D3eyxz4AI6ItcDlwBOl6bdKN2/LbA/F1EngzyLiqYjYXNpWZub+svw6sLI1pQG1O+HV/wedC/us0f6Za++7f0ztL8gR6yLimYj4i4j4+RbUM97vbq7ss58HDmTmrrq2Wd9fYz4jZux9VqUwmHMiohf4Y+CzmXkUuBv4KeAjwH5qXdRW+LnMvAK4Abg9Ij5evzJr/dKWHJMctduifhL4H6VpruyzUa3cP+cTEZ8HhoFvlab9wAcz83LgXwL/PSL6ZrGkOfe7G+NTvPePjlnfX+N8Roya7vdZlcJgH7Cm7vHq0tYSEdFB7Zf8rcz8LkBmHsjMs5l5DvhDZqhrPJHM3Fe+vwH8SanjwEi3s3x/oxW1UQuopzPzQKlxTuwzGu+fOfG+i4h/BPwy8BvlQ4QyDHOwLD9FbWz+b81WTef53bV8n0VEO/CrwHdG2mZ7f433GcEMvs+qFAZPAusjYl356/IWYFsrCiljkfcCL2XmV+va68f4fgV4fuxzZ6G2RRGxeGSZ2uTj89T21aay2SbgodmurXjPX2tzYZ8VjfbPNuDWcrTH1cCRum7+rIiI64HfBj6ZmSfr2gcioq0sXwKsB3bPYl2NfnfbgFsioisi1pW6fjhbdRW/CPw4M/eONMzm/mr0GcFMvs9mY2Z8rnxRm3H/CbVE/3wL6/g5at27Z4Gd5etG4JvAc6V9G3BxC2q7hNqRHD8CXhjZT8By4FFgF/DnwLIW1LYIOAj017XN+j6jFkb7gTPUxmZva7R/qB3d8fXynnsO2NCC2gapjSePvNf+oGz7D8rveCfwNPCJWa6r4e8O+HzZZy8DN8xmXaX9j4DfHLPtbO6vRp8RM/Y+83IUkqRKDRNJkhowDCRJhoEkyTCQJGEYSJIwDCRJGAaSJOD/A2dtLJ23nIpZAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, rmse_error_test = lrcn_model.evaluate(x_test, y_test, batch_size=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcsoIBY1rHHk",
        "outputId": "fb156dbc-1d75-45cc-9448-2137aeddce10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3916 - root_mean_squared_error: 0.6258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading model for predictions "
      ],
      "metadata": {
        "id": "EAu8_AwQqHI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lrcn_model = keras.models.load_model(path)"
      ],
      "metadata": {
        "id": "vbDE6SQYqIu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = np.mean(lrcn_model.predict(np.array(x_test))[1])\n",
        "print(\"prediction\", prediction)\n",
        "print('actual', np.array(y_test)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOc-D24TFI6Q",
        "outputId": "2cf5b23c-441c-46c0-dab4-5960bc2adb4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction 98.83963\n",
            "actual [97.9]\n"
          ]
        }
      ]
    }
  ]
}